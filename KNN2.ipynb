{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "082e3967-e199-48c6-aa8d-2e23d58266c5",
   "metadata": {},
   "source": [
    "# Q1.\n",
    "### What is the main difference between the Euclidean distance metric and the Manhattan distance metric in KNN? How might this difference affect the performance of a KNN classifier or regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c988fd-7adc-4762-b20c-9f13331dd64a",
   "metadata": {},
   "source": [
    "- Euclidean distance is the straight-line distance between two points in Euclidean space.\n",
    "- Manhattan distance, also known as L1 distance is the sum of the absolute differences of their coordinates.\n",
    "- Scale Sensitivity: Euclidean distance is more sensitive to differences in individual feature magnitudes due to squaring, while Manhattan distance treats all feature differences linearly.\n",
    "- Feature Correlation: Euclidean distance assumes features are uncorrelated and equally weighted, which might not always be the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275ba004-5ad2-478b-86c1-8d126de1e7e9",
   "metadata": {},
   "source": [
    "# Q2.\n",
    "###  How do you choose the optimal value of k for a KNN classifier or regressor? What techniques can be used to determine the optimal k value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb8eb45-283d-4723-af85-3cf01d9b4d81",
   "metadata": {},
   "source": [
    "- Cross-Validation: Perform k-fold cross-validation to evaluate different values of k and select the one with the best performance.\n",
    "- Grid Search: Use a grid search technique to try a range of k values and select the best performing one based on a scoring metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4f2797-905a-4e7e-98f9-6be0aa0d2e85",
   "metadata": {},
   "source": [
    "# Q3.\n",
    "### How does the choice of distance metric affect the performance of a KNN classifier or regressor? In what situations might you choose one distance metric over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b6f0c3-0e14-4d0a-b57a-93823c87a3d3",
   "metadata": {},
   "source": [
    "- If the features have different units or scales, Euclidean distance might be less appropriate without normalization. Manhattan distance can sometimes be more robust to different feature scales.\n",
    "-  If there is reason to believe that the relationship between features is linear, Manhattan might be preferred. If the relationship is more geometric or Euclidean, then Euclidean distance might be better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcafe2d-9daf-4428-9a7c-6e87a4da86b4",
   "metadata": {},
   "source": [
    "# Q4.\n",
    "### What are some common hyperparameters in KNN classifiers and regressors, and how do they affect the performance of the model? How might you go about tuning these hyperparameters to improve model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0730f6-5627-4de1-aae7-ac15d8b65449",
   "metadata": {},
   "source": [
    "- k: Determines the number of nearest neighbors considered. Too low a value can lead to overfitting, while too high a value can lead to underfitting.\n",
    "- Distance Metric: Affects how distances between points are calculated and can significantly impact the performance.\n",
    "- Weight Function: Whether all neighbors are weighted equally or weighted by distance can also affect performance.\n",
    "\n",
    "Tuning Hyperparameters :\n",
    "\n",
    "- Grid Search: Systematically explore a range of hyperparameter values and select the best combination.\n",
    "- Random Search: Randomly sample hyperparameter values within given ranges and evaluate performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec12bfd-48ff-466e-8cad-8bd5c12fbc75",
   "metadata": {},
   "source": [
    "# Q5.\n",
    "### How does the size of the training set affect the performance of a KNN classifier or regressor? What techniques can be used to optimize the size of the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33efbf3-8109-49bc-9cfc-62779ba758ff",
   "metadata": {},
   "source": [
    "- Larger Training Set: Generally leads to better performance as KNN relies heavily on the training data. More data can help in better defining the decision boundary.\n",
    "- Computational Cost: Larger datasets increase computation time for finding nearest neighbors during prediction.\n",
    "\n",
    "Optimizing Training Set Size :\n",
    "\n",
    "- Data Augmentation: Create synthetic data to increase the training set size.\n",
    "- Dimensionality Reduction: Techniques like PCA can reduce the number of features, making the problem more tractable with a given training set size.\n",
    "- Subsampling: Use techniques like stratified sampling to ensure representative training subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476c59fa-b58e-4b78-bd55-e1c89d8c79d5",
   "metadata": {},
   "source": [
    "# Q6.\n",
    "### What are some potential drawbacks of using KNN as a classifier or regressor? How might you overcome these drawbacks to improve the performance of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ead0ea1-3709-4564-a964-931dc989eb26",
   "metadata": {},
   "source": [
    "- Computational Inefficiency: KNN can be slow for large datasets as it requires distance computation with all training samples.\n",
    "- Sensitivity to Noise: KNN can be sensitive to noisy data and outliers.\n",
    "- Curse of Dimensionality: In high-dimensional spaces, the distance metrics can become less informative.\n",
    "\n",
    "Overcoming Drawbacks :\n",
    "\n",
    "- Efficient Data Structures: Use KD-trees or Ball-trees for efficient nearest neighbor searches.\n",
    "- Dimensionality Reduction: Apply PCA or other dimensionality reduction techniques to reduce the feature space.\n",
    "- Data Preprocessing: Normalize or standardize the data, and apply noise reduction techniques.\n",
    "- Hybrid Models: Combine KNN with other algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
